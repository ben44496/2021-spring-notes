# Privacy
## Three Philosophies
1. Accessibility Privacy (1800's)
	1. Freedom from unwarranted intrusion
	2. Physical access to your person
	3. Fourth Amendment (search and seizure)
2. Decisional Privacy (1900's)
	1. Freedom from interference in personal affairs
	2. Personal choices, plans, and decisions are yours
	3. First Amendment, Griswold v. Connecticut, Roe vs. Wade
3. Informational Privacy (2000's)
	1. Control over flow of personal information
	2. How can your information be gathered, stored, mined, combined...
	3. Legal Decisions ongoing (Policy Vacuum)

### Moor's Theory of Privacy
- Descriptive Privacy
	- privacy protected by physical means
	- descriptive privacy can be *lost*
- normative privacy
	- privacy protected by policies
	- normative privacy can be *violated*

### Nissenbaum's Theory of Privacy
- Privacy as "contextual integrity"
	- Norms depend on context (e.g. school/family)
1. Norms of appropriateness
	1. Should information be gathered/divulged?
2. Norms of distribution
	1. Should information be shared?
	2. Transfers data to a new context
- Violating norms results in a *breach*

### Hartzog's Theory of Privacy
1. Trust - willingness to make oneself vulnerable to actions of others
2. Obscurity - an observer does not have the context to make sense of an individual
3. Autonomy - a person can engage in relationships of trust and maintain reliable zones of obscurity

Example: Doxxing can be towards wrong person, use biker doxxing?

## Privacy Vocabulary
- **Personal Identifying Information (PII)** - information used to uniquely identify a person
- **Nonpublic Personal Information (NIP)** - confidential and private information about a person (ie. medical records, bank accont statement)
- **Public Personal Information (PPI)** - public information about a person
- **Metadata** - data describing other data

## Data gathering
- **Dataveillance** - data surveillance
- Data from: cookies, search history, emails, GPS, WiFi, messaging, credit history, etc.

### Personal Data is like radioactive waste
- Easy to generate, easy to store in short term, harmful if release, almost impossible to dispose of

### Exchanging
- Data can be *merged* and *matched*
	- integrated into a composite
	- unique identifiers search multiple databases

### Mining
- **Data mining** - indirectly gathers personal information through pattern matching
- Difficult to regulate
	- Patterns are *implicit* in the data
	- Data is typically *nonconfidential*
	- Data is not necessarily *exchanged*

### Deanonymization
- Mining to derive PII from anonymous data
- Workflow:
	- identify unique users in the data
	- correlate features of individual with public data
- Examples
	- AOL search history
	- Netflix subscriber data deanonymized using IMDB
	- Surnames from raw DNA sequence data

### Informed Consent
- **Informed consent** - user understands and agrees to how the data is used
- Current uses of information are *opaque* to user
	- Don't read TOS, can't predict data mining

### Privacy-Enhancing Technology (PET)
- End to End Encryption (E2EE)
- Anonymizing tools
- Problems: You have to know how to use this, some (VPN services) don't even actually protect privacy

## Policies
- Self-Regulation
	- TRUSTe
- US Laws
	- FCRA ('80), FERPA ('74), ECPA ('86), ...

### Minimalism
- Design to protect users
- Only collect necessary data
- Store data as briefly as is needed
- Make sure it is deleted