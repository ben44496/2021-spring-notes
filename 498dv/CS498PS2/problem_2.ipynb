{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = np.load(\"input.npy\")\n",
    "# output = np.load(\"output.npy\")\n",
    "# x = np.array([input**2, input]).T\n",
    "# y = output.reshape((output.shape[0], -1))\n",
    "\n",
    "# tts = train_test_split(x, y)\n",
    "# train_x = tts[0][0]\n",
    "# train_y = tts[2][0]\n",
    "# test_x = tts[1][0]\n",
    "# test_y = tts[3][0]\n",
    "\n",
    "# def gen_x(N, d):\n",
    "#     arr = np.random.randint(100, size=(N,d))\n",
    "#     return arr\n",
    "\n",
    "# def gen_y(x):\n",
    "#     s = np.sum(x, axis=1)\n",
    "#     boolean = x[:,0] / s\n",
    "#     return (boolean >= 0.5).astype(np.float32)\n",
    "\n",
    "def gen_x(N, d):\n",
    "    arr = np.random.randint(100, size=(N,d))\n",
    "    return arr\n",
    "\n",
    "def gen_y(x):\n",
    "    return (x[:, 0] >= 50).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Neural Networks\n",
    "## Problem 2.1 Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_entropy_loss(w, x, y_g):\n",
    "#     # y_g is {-1, 1}\n",
    "#     return -y_g*np.log(w*x) - (1-y_g)*np.log(1-w*x)\n",
    "\n",
    "def cross_entropy_loss(y_p, y_g):\n",
    "    # y_g is {-1, 1}\n",
    "    return -y_g*np.log(y_p) - (1-y_g)*np.log(1-y_p)\n",
    "\n",
    "def cross_entropy_deriv(w, x, y_g, predict):\n",
    "    y_p = predict(w, x)\n",
    "    return (y_g / y_p) + (1-y_g) / (1-y_p)\n",
    "\n",
    "def sigmoid(x):\n",
    "    # assert type(x) == np.ndarray\n",
    "    denominator = 1 + np.exp(-x)\n",
    "    return 1 / denominator\n",
    "\n",
    "def sgn(x):\n",
    "    return np.sign(x)\n",
    "\n",
    "def hinge_loss(w, x, y_g, predict):\n",
    "    y_p = predict(w, x)\n",
    "    return np.sum(np.maximum(0, 1-y_p*y_g))\n",
    "\n",
    "def hinge_deriv(w, x, y_g, predict):\n",
    "    y_p = predict(w, x)\n",
    "    if y_p*y_g < 1:\n",
    "        return np.sum(-y_g*x)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"Currently only supports a very specific implementation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y, nlf, ell, dell, loss, lr=0.01, tol=0.01):\n",
    "        assert (x.shape[0], 1) == (y.shape[0], 1), \"Make sure your matrices are (N,d) and (N,1)\" # (Class, dim)\n",
    "        # assert len(x.shape) == 2, \"Make sure x is 2D. If not do reshape((N, -1))\"\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "\n",
    "        self.nlf_ = nlf # Non linear function (sigmoid)\n",
    "        self.ell_ = ell\n",
    "        self.dell_ = dell # Derivative of Loss Function\n",
    "        self.loss_ = loss\n",
    "        self.lr_ = lr\n",
    "        self.tol_ = tol\n",
    "        self.num_points_ = x.shape[0] # N\n",
    "        self.dim_ = x.shape[1] + 1 # Add one to dimension for bias, d\n",
    "        self.w_ = np.random.rand(self.dim_) # Initialize random weights [0, 1)\n",
    "        self.w_ /= la.norm(self.w_)\n",
    "        self.x_ = x.copy()# Append a one at beginning for bias\n",
    "        # np.insert(x.reshape((self.num_points_, -1)), 0, np.ones(self.num_points_), axis=1) \n",
    "        self.y_g = y.T.flatten().copy()\n",
    "\n",
    "    def mini_batch_gradient_descent(self, lr=0.01, batch_size=5, epochs=25):\n",
    "        error = []\n",
    "        for _ in range(epochs):\n",
    "            idx = np.random.randint(self.num_points_, size=batch_size)\n",
    "            grad = 0\n",
    "            err = 0\n",
    "            for i in idx:\n",
    "                err += self.ell_(self.w_, self.x_[i], self.y_g[i], self.predict)\n",
    "                grad += self.dell_(self.w_, self.x_[i], self.y_g[i], self.predict)\n",
    "            grad /= idx.shape[0]\n",
    "            err /= idx.shape[0]\n",
    "            error.append((_, err))\n",
    "            self.w_ = self.w_ - lr * grad\n",
    "        return self.w_, error\n",
    "    \n",
    "    def predict(self, w, x):\n",
    "        \"\"\"Performs feed forward with weight summation and non-linear activation\n",
    "        \"\"\"\n",
    "        # assert row.shape[0] == self.dim_, str(row.shape) + \" \" + str(self.dim_)\n",
    "        mean = np.average(x)\n",
    "        std = np.std(x)\n",
    "        normalized_x = (x - mean) / std\n",
    "        return self.nlf_(np.sum(w[1:] * normalized_x) + w[0])\n",
    "        \n",
    "    def prediction(self, x):\n",
    "        return self.predict(self.w_, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = gen_x(100, 3)\n",
    "train_y = gen_y(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.2),\n",
       " (1, 0.2),\n",
       " (2, 0.4),\n",
       " (3, 0.6),\n",
       " (4, 0.4),\n",
       " (5, 0.8),\n",
       " (6, 0.2),\n",
       " (7, 0.8),\n",
       " (8, 0.2),\n",
       " (9, 0.4),\n",
       " (10, 0.6),\n",
       " (11, 0.6),\n",
       " (12, 0.4),\n",
       " (13, 1.0),\n",
       " (14, 0.2),\n",
       " (15, 0.4),\n",
       " (16, 0.4),\n",
       " (17, 0.6),\n",
       " (18, 0.4),\n",
       " (19, 0.4),\n",
       " (20, 0.2),\n",
       " (21, 0.6),\n",
       " (22, 0.2),\n",
       " (23, 0.6),\n",
       " (24, 0.2),\n",
       " (25, 0.2),\n",
       " (26, 0.0),\n",
       " (27, 0.2),\n",
       " (28, 0.2),\n",
       " (29, 0.2),\n",
       " (30, 0.4),\n",
       " (31, 0.6),\n",
       " (32, 0.4),\n",
       " (33, 0.6),\n",
       " (34, 0.6),\n",
       " (35, 0.8),\n",
       " (36, 0.4),\n",
       " (37, 0.6),\n",
       " (38, 0.4),\n",
       " (39, 0.6),\n",
       " (40, 0.0),\n",
       " (41, 0.6),\n",
       " (42, 0.4),\n",
       " (43, 0.6),\n",
       " (44, 0.6),\n",
       " (45, 0.2),\n",
       " (46, 0.6),\n",
       " (47, 0.4),\n",
       " (48, 0.4),\n",
       " (49, 0.2),\n",
       " (50, 0.0),\n",
       " (51, 0.2),\n",
       " (52, 0.6),\n",
       " (53, 0.6),\n",
       " (54, 0.6),\n",
       " (55, 0.6),\n",
       " (56, 0.6),\n",
       " (57, 0.6),\n",
       " (58, 0.4),\n",
       " (59, 0.4),\n",
       " (60, 0.4),\n",
       " (61, 0.4),\n",
       " (62, 0.2),\n",
       " (63, 0.4),\n",
       " (64, 0.6),\n",
       " (65, 0.4),\n",
       " (66, 0.4),\n",
       " (67, 0.4),\n",
       " (68, 0.4),\n",
       " (69, 0.4),\n",
       " (70, 0.2),\n",
       " (71, 0.4),\n",
       " (72, 0.4),\n",
       " (73, 0.6),\n",
       " (74, 0.6),\n",
       " (75, 0.6),\n",
       " (76, 0.4),\n",
       " (77, 0.0),\n",
       " (78, 0.6),\n",
       " (79, 0.8),\n",
       " (80, 0.4),\n",
       " (81, 0.6),\n",
       " (82, 0.0),\n",
       " (83, 0.8),\n",
       " (84, 0.4),\n",
       " (85, 0.4),\n",
       " (86, 0.6),\n",
       " (87, 0.2),\n",
       " (88, 0.4),\n",
       " (89, 0.2),\n",
       " (90, 0.4),\n",
       " (91, 0.6),\n",
       " (92, 0.6),\n",
       " (93, 0.0),\n",
       " (94, 0.2),\n",
       " (95, 0.8),\n",
       " (96, 0.4),\n",
       " (97, 0.2),\n",
       " (98, 0.4),\n",
       " (99, 0.4)]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p = Perceptron(train_x, train_y, sigmoid, cross_entropy_loss, cross_entropy_deriv, cross_entropy_loss)\n",
    "p = Perceptron(train_x, train_y, sgn, hinge_loss, hinge_deriv, cross_entropy_loss)\n",
    "w, error = p.mini_batch_gradient_descent(batch_size=5, epochs=100)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 1.0, array([0.], dtype=float32))"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = gen_x(1, 3)\n",
    "test_y = gen_y(test_x)\n",
    "test_x[0,0], p.prediction(test_x), test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-327-f0ac818ec00c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_entropy_deriv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'loss'"
     ]
    }
   ],
   "source": [
    "p = Perceptron(train_x, train_y, sigmoid, cross_entropy_deriv, cross_entropy_loss)\n",
    "y_p = p.feed_forward()\n",
    "y_p[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_deriv(y_p[:5], train_y[:5].flatten())\n",
    "# # np.apply_along_axis(cross_entropy_deriv, 0, )\n",
    "# # train_y[:5].T\n",
    "# y_p.shape, train_y.shape\n",
    "idx = np.random.randint(y_p.shape[0], size=3)\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e018137ffda6e84bad91b13a13082b3438e14729982a434c35ce4ecabfe2410"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
