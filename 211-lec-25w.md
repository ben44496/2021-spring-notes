# Data Science and Research Ethics

## Intellectual Honesty
- Pursue the truth above your personal beliefs
- Present all relevant facts
- Present facts ina turthful and unbiased manner
- Give credit to tohers' work
- Do not knowingly make fallacious arguments
- Disclose your biases and conflicts of interest

## Peer Review
- Research should be subject to scrutiny by peers before it is published
- Peer review is a form of quality control and self-regulation
- Do not go directly to press with research findings (journalists are not experts in your field)

# Human Subjects
## The Nuremberg Code
1. Informed consent of subjects
2. Positive results for society
3. Based on previous knowledge
4. Avoid unnecessary harm
5. No risk of death or disability
6. Risks proportional to benefits
7. Facilities must protect subjects
8. All staff must be trained and qualified
9. Subjects are free to quit
10. Stop the experiment if there is danger

## Belmon Report
1. Respect for persons
2. Beneficence
3. Justice
- National Comissions for the Protection of Human Subjects of Biomedical and Behavioral Research
- Research needs to deal with IRB (Institutional Review Board)

## Informed Consent
Informed consent is a decision to participate in research, taken by a competent individual who has received the necessary information; who has adequately understood the information; and who, aftercnonsidering the information, has arrived at a decision without having been subjected to coercion, undue influence or inducement, or intimidation
- WHO International Ethical Guidelines for Biomedical Research Involving Human Subjects

# Data Science Ethics
## Machine Learning and Data Mining
- Basic information on supervised and unsupervised learning

## Data Validity
- Sample data must be representative to draw meaningful conclusions
	- Are Twitter users representative of the population?
	- Are Amazon reviews representative of consumer opinions?
- Can weight sampled data to better represent the population

# Evaluating Machine Learning
## Overfitting
- When a machine learning algorithm learns the specifics of a training set that don't generalize to untrained data
- This can be caused by:
	- an overly ocmplex model
	- training data with many irrelevant features
	- unrepresentative trianing data

## Paradox of the False Positive
- In highly skewed datasets the probability of a true positive is lower than the probability of a false positive

## Prosecutor's Fallacy
- Assuming the prior probbility of a match is equal conditional probability of innocence
	- We were given p(match|innocent) = .0001
	- We actually want is p(innocent|match)
- Using a binomial distribution, probability of at least one match is 0.988

## P-Hacking
- Only reporting the interesting results in a series of studies
- Manipulating data to achieve seemingly statistically significant results
	- Testing multiple conditions or measures, but only report significant ones
	- Exclude or filter data until the results is significant
	- Transform the data to get a significant result
- Many researchers do this without realizing it
- Pay attention to **effect size** not just statistical significance

## Accuracy Paradox
- Given a test dataset, a classifier can produce the following outocmes:
	- True Positive
	- False Positive
	- True Negative
	- False Negative
- Accuracy given by $\frac{TP + TN}{Total}$ is frequently reported, but not usually a good measure
- Better to use measures like:
	- Sensitivity $\frac{TP}{TP+FN}$
	- ...

Note: Occam's razor and regression to the mean
## Regression to the Mean
- If we sample extreme data points from a distribution, future data points are more likely to be nearer to the mean
- Lots of sports "statistics" are like this